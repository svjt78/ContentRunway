# ContentRunway Test Suite

## ğŸ§ª Test Scripts Usage Guide

This directory contains comprehensive test scripts for debugging and validating the ContentRunway multi-agent pipeline.

## ğŸ“ Directory Structure

```
tests/
â”œâ”€â”€ agents/                          # Individual agent tests
â”‚   â”œâ”€â”€ test_research_agent_standalone.py    # Research agent testing (START HERE)
â”‚   â”œâ”€â”€ test_research_output_validation.py   # Research output validation
â”‚   â”œâ”€â”€ test_content_curator.py              # Topic selection testing
â”‚   â””â”€â”€ test_quality_gates.py                # Quality validation testing
â”œâ”€â”€ integration/                     # End-to-end pipeline tests
â”‚   â”œâ”€â”€ test_pipeline_integration.py         # Full pipeline execution
â”‚   â””â”€â”€ test_database_integration.py         # Database persistence testing
â””â”€â”€ README.md                        # This file
```

## ğŸš€ Quick Start

### **PRIORITY: Start with Research Agent Testing**

The pipeline issue likely stems from the research agent, so start here:

```bash
# Navigate to project root
cd /path/to/ContentRunway

# Run research agent standalone test
python tests/agents/test_research_agent_standalone.py

# Check results
cat test_results/research_agent_test_results.json
```

### **Step-by-Step Testing Sequence**

1. **Research Agent** (Most Critical)
   ```bash
   python tests/agents/test_research_agent_standalone.py
   python tests/agents/test_research_output_validation.py
   ```

2. **Content Curator**
   ```bash
   python tests/agents/test_content_curator.py
   ```

3. **Quality Gates**
   ```bash
   python tests/agents/test_quality_gates.py
   ```

4. **Database Integration**
   ```bash
   python tests/integration/test_database_integration.py
   ```

5. **Full Pipeline Integration**
   ```bash
   python tests/integration/test_pipeline_integration.py
   ```

## ğŸ“Š Expected Output Files

Each test generates detailed results:

- `test_results/research_agent_test_results.json` - Research agent performance data
- `test_results/pipeline_test_results_*.json` - Pipeline execution results
- Console logs with real-time test progress and diagnostics

## ğŸ” What Each Test Does

### **Research Agent Standalone** (`test_research_agent_standalone.py`)
- âœ… Tests ResearchCoordinatorAgent with multiple queries
- âœ… Tests domain-specific agents (IT Insurance, AI, Agentic AI, etc.)
- âœ… Tests WebResearchTool functionality
- âœ… Validates output structure and content quality
- **Purpose**: Identify if research agent is working or failing

### **Research Output Validation** (`test_research_output_validation.py`)
- âœ… Validates research result structure
- âœ… Checks source and topic field requirements
- âœ… Validates score ranges and data types
- **Purpose**: Ensure research agent returns properly formatted data

### **Content Curator** (`test_content_curator.py`)
- âœ… Tests topic selection logic
- âœ… Tests scoring algorithms
- âœ… Tests edge cases (all high/low quality topics)
- **Purpose**: Verify topic curation works correctly

### **Quality Gates** (`test_quality_gates.py`)
- âœ… Tests all 4 quality validation agents individually
- âœ… Tests parallel execution performance
- âœ… Tests scoring algorithms and thresholds
- **Purpose**: Ensure quality validation is working

### **Database Integration** (`test_database_integration.py`)
- âœ… Tests topic creation and retrieval
- âœ… Tests content draft creation and retrieval
- âœ… Tests research source storage
- âœ… Tests quality assessment storage
- **Purpose**: Verify data is actually being saved to database

### **Pipeline Integration** (`test_pipeline_integration.py`)
- âœ… Tests complete end-to-end pipeline execution
- âœ… Tests step-by-step execution for debugging
- âœ… Tests error handling and recovery
- **Purpose**: Identify where the pipeline is failing

## ğŸ› Troubleshooting

### **Issue: "No module named 'langgraph'"**
```bash
# Make sure you're in the right directory and Python path is set
cd /path/to/ContentRunway
export PYTHONPATH="${PYTHONPATH}:$(pwd)/langgraph"
```

### **Issue: "No module named 'backend'"**
```bash
# Make sure backend modules are accessible
export PYTHONPATH="${PYTHONPATH}:$(pwd)/backend"
```

### **Issue: Database connection errors**
```bash
# Make sure Docker services are running
docker-compose up -d
```

### **Issue: Import errors for agents**
Check if the agent files exist:
```bash
ls -la langgraph/contentrunway/agents/
```

## ğŸ“ˆ Success Criteria

### **Research Agent Tests Should Show:**
- âœ… 10+ sources found per domain
- âœ… 5+ topic ideas generated
- âœ… Execution time < 30 seconds per test
- âœ… No import or connection errors

### **Database Tests Should Show:**
- âœ… Topics successfully created and retrieved
- âœ… Content drafts successfully created and retrieved
- âœ… No database connection errors

### **Pipeline Tests Should Show:**
- âœ… All pipeline steps complete successfully
- âœ… Real content generated (not simulation)
- âœ… Final quality score > 0.85

## ğŸ”§ Debugging Tips

### **If Research Agent Fails:**
1. Check if `WebResearchTool` is properly implemented
2. Check if domain agents can be imported
3. Check if API keys are set for external services
4. Look for network connectivity issues

### **If Database Tests Fail:**
1. Check database connection strings
2. Verify table schemas match model definitions
3. Check if sync database functions exist
4. Ensure Docker PostgreSQL is running

### **If Pipeline Never Executes Real Agents:**
1. Check `backend/app/tasks/pipeline_tasks.py:224` - This is where it falls back to simulation
2. Add logging to see why LangGraph execution fails
3. Check imports and dependencies for LangGraph components

## ğŸ“ Analyzing Results

### **Research Agent Results:**
```json
{
  "test_case": 1,
  "query": "AI agents and multi-agent systems", 
  "sources_found": 15,
  "topics_generated": 8,
  "execution_time": 12.5,
  "success": true,
  "errors": []
}
```

### **Key Metrics to Watch:**
- **sources_found**: Should be > 5 per test
- **topics_generated**: Should be > 3 per test
- **execution_time**: Should be < 30s per test
- **success**: Should be `true` for most tests
- **errors**: Should be empty array

## ğŸ¯ Next Steps After Testing

1. **Fix any failing tests** before proceeding
2. **Identify root cause** of "success but no content" issue
3. **Fix LangGraph pipeline execution** to stop falling back to simulation
4. **Re-run full pipeline** and verify content appears in database
5. **Check content tab** in frontend to confirm content is visible

## ğŸ’¡ Pro Tips

- **Run tests individually** first to isolate issues
- **Check console output** for detailed error messages  
- **Save test results** for comparison after fixes
- **Use step-by-step pipeline test** for detailed debugging
- **Start with research agent** - it's the most likely failure point

---

**Need Help?** 
- Review the detailed error messages in console output
- Check the JSON result files for specific failure details
- Run tests individually to isolate specific issues
- Verify all dependencies are properly installed